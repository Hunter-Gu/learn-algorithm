# 二叉查找树

二叉查找树最大的特点是：**支持动态数据集合的快速插入、删除、查找操作**。

之前说过，散列表也是支持这些操作的，并且散列表的这些操作比二叉查找树更高效，时间复杂度是 O(1)。既然有了这么高效的散列表，使用二叉树的地方是不是都可以替换成散列表呢？有没有哪些地方是散列表做不了，必须要用二叉树来做的呢？

## 是什么

顾名思义，二叉查找树是为了实现快速查找而生的。并且，它不仅仅支持快速查找一个数据，还支持快速插入、删除一个数据。它是怎么做到这些的呢？

这些都依赖于二叉查找树的特殊结构。树中的任意一个节点，二叉查找树要求：

- 左子树中的每个节点的值，都小于这个节点的值
- 右子树中的每个节点的值，都大于这个节点的值

![二叉查找树](@imgs/f3bb11b6d4a18f95aa19e11f22b99bae.jpg)

## 操作

### 查找

- 先取根节点，如果等于要查找的数据则直接返回
- 要查找的数据小于根节点，在左子树中递归查找
- 要查找的数据大于根节点，在右子树中递归查找

<!-- TODO 代码 -->

### 插入

- 如果要插入的数据比节点的数据大，则处理右子树
  - 右子树为空：将新数据直接插到右子节点的位置
  - 右子树不为空：递归遍历右子树，查找插入位置
- 如果要插入的数据比节点数值小，则处理左子树
  - 左子树为空：将新数据插入到左子节点的位置
  - 左子树不为空：递归遍历左子树，查找插入位置

<!-- TODO 代码 -->

### 删除

删除操作比较复杂，针对要删除节点的子节点数量，要分三种情况处理：

- 要删除的节点没有子节点：将该节点从父节点中删除即可
- 要删除的节点有一个子节点：更新父节点的指针，指向被删节点的子节点
- 要删除的节点有两个子节点：
  - 找到被删节点的右子树中的最小节点，替换到被删节点上
  - 删除最小节点（最小节点肯定没有左节点）

实际上，二叉查找树的删除操作，有个非常简单、取巧的方法 -- 将要删除的节点标记为“已删除”，但是并不真正从树中将这个节点去掉。这样比较浪费内存空间，但是删除操作就变得简单了很多。而且，这种处理方法也并没有增加插入、查找操作代码实现的难度。

<!-- TODO 代码 -->

### 其他操作

二叉查找树支持**快速地查找最大节点和最小节点、前驱节点和后继节点**。

另外，二叉查找树还有一个重要的特性：通过中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)。

<!-- TODO 代码 -->

## 重复数据

实际开发时，二叉查找树中存储的一般都是对象，以对象的某个字段作为键（key）来构建二叉查找树，而对象中的其他字段叫作卫星数据。

那么如果两个对象的键（key）相同，该如何处理？

### 同一个节点存储多个数据

方法一，二叉查找树中每一个节点可以存储多个数据，所以可以通过链表和支持动态扩容的数组等数据结构，把键（key）相同的数据存储在同一个节点上。

### 插入右子树

方法二，把这个新插入的数据当作大于这个节点的值来处理（将这个要插入的数据放到这个节点的右子树）。

![插入到右子树](@imgs/3f59a40e3d927f567022918d89590a5f.jpg)

#### 查找

这种方法在查找数据时，为了把键值相等的所有节点都找出来，遇到键值相同的节点，并不停止查找操作，而是继续在**右子树**中查找，直到遇到叶子节点，才停止。

![查找](@imgs/fb7b320efd59a05469d6d6fcf0c98eff.jpg)

#### 删除

这种方法在删除数据时，需要先查找到所有要删除的节点，然后再按照[之前的删除方法](/tree/binary-search-tree.html#删除)依次删除。

![删除](@imgs/254a4800703d31612c0af63870260517.jpg)

## 时间复杂度

二叉查找树的形态多种多样，如图，同一组数据就可以构造出三种二叉查找树，并且它们的查找、插入、删除操作的时间复杂度都不同。

![同一组数据的多种二叉查找树](@imgs/e3d9b2977d350526d2156f01960383d9.jpg)

最糟糕的情况就如图 (1) 所示，根节点的左右子树极度不平衡，已经退化为链表了，所以查找操作的时间复杂度也就变为了 O(n)。

最理想情况下，二叉查找树是一棵完全二叉树（或满二叉树）。

不管是插入、删除还是查找，**时间复杂度和树的高度成正比**，即 O(height)。而树的高度等于最大层数减 1，那么问题就变成了如何求完全二叉树的层数？

对于包含 n 个节点的完全二叉树来说，下一层节点的个数是上一层的 2 倍，那么第 k 层的节点个数就是 2 ^ (k - 1)，所以最后一层的节点数量的范围就是 1 ~ 2 ^ (L - 1)，L 为最大层数。得到 n 和 L 的关系式：

```
n >= 1 + 2 + 4 + 8 + ... + 2 ^ (L - 2) + 1
n <= 1 + 2 + 4 + 8 + ... + 2 ^ (L - 2) + 2 ^ (L - 1)
```

得到 L 的范围是 [log(n + 1), logn + 1]。显然，极度不平衡的二叉查找树的查找性能是比较差的。我们需要一种在任何时候，都能保持任意节点左、右子树都比较平衡的二叉查找树。

## 思考

### 二叉树 vs. 散列表

- 散列表的插入、删除、查找操作的时间复杂度可以做到常量级的 O(1)，非常高效
- 二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 O(logn)

相对散列表，二叉查找树好像并没有什么优势，那为什么还要用二叉查找树呢？

- 数据有序
  - 散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序
  - 二叉查找树只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列
- 扩容
  - 散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定
  - 平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)
- 散列冲突。散列表会有哈希冲突的情况，所以尽管散列表的查找等操作的时间复杂度是常量级的，但这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。再加上 Hash 函数也需要耗时，也不一定就比平衡二叉查找树的效率高
- 数据结构的复杂度
  - 散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等
  - 平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定
- 装载因子。为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间

综上，二叉查找树在某些方面还是优于散列表的，这两者的存在并不冲突。实际的开发过程中，需要结合具体的需求来选择使用哪一个。

### 求二叉树的高度

如何求出一棵给定二叉树的确切高度？

两种思路：

- 1.深度优先思想的递归，分别求左右子树的高度。当前节点的高度就是左右子树中较大的那个+1；
- 2.第二种可以采用层次遍历的方式，每一层记录都记录下当前队列的长度，这个是队尾，每一层队头从0开始。然后每遍历一个元素，队头下标+1。直到队头下标等于队尾下标。这个时候表示当前层遍历完成。每一层刚开始遍历的时候，树的高度+1。最后队列为空，就能得到树的高度。
