# Hash（散列）算法

## 是什么

将任意长度的二进制值串映射为固定长度的二进制值串（散列值）。

一个优秀的 hash 算法应该满足以下几点要求：

- 不能从 hash 值推导出原始数据（即单向 hash 算法）
- 对输入数据敏感（原始数据只进行了一丁点修改，得到的 hash 值也大不相同）
- hash 冲突的概率很小
- 执行效率尽量高，针对较长文本，也能快速计算

### MD5

以 MD5 这种 Hash 算法举例说明。MD5 的散列值是 128 位的，为了方便表示，把转化成了 16 进制编码：

```
MD5("我今天讲哈希算法！") = 425f0d5a917188d2c3c3dc85b5e4f2cb

MD5("我今天讲哈希算法")   = a1fb91ac128e6aa37fe42c663971ac3d
```

## 应用

### 安全加密

最常用于加密的 Hash 算法有：

- MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）
- SHA（Secure Hash Algorithm，安全散列算法）
- DES（Data Encryption Standard，数据加密标准）
- AES（Advanced Encryption Standard，高级加密标准）

对用于加密的 Hash 算法来说，有两点格外重要：

- 很难根据 Hash 值推导出原始数据
- 散列冲突的概率很小

不管是什么 Hash 算法，都没办法做到完全没有散列冲突，只能尽量减少冲突的概率。这是组合数学中非常基础的理论 - 鸽巢原理，即 10 个鸽巢，有 11 只鸽子，那肯定有 2 只鸽子在 1 个鸽巢中。

Hash 算法产生的 Hash 值长度是固定且有限的。如 MD5 的 Hash 值长度是 128 位，那最多可以表示 2^128 个数据，如果对 2^128 + 1 个数据求 Hash 值，就必然会存在 Hash 值相同的情况。

也就是说，Hash 值越长的 Hash 算法，散列冲突的概率越低。同样的，越复杂、越难破解的加密算法，需要的计算时间也就越长，开发时需要权衡破解难度和计算时间。

### 唯一标识

当你在图库中搜索一张图时，不能单纯的用图片的元信息（如名称）来对比，因为可能存在同名不同图、同图不同名的情况。那该如何搜索呢？

任何文件在计算机中都可以表示为二进制，可以【将要查找的图片的二进制】和【图库中所有图片的二进制】进行比对。但是图片小的有 KB，大的有 MB，转化为二进制就是一个非常长的二进制串，对比起来非常耗时。有没有更快的方法？

给每个图片取一个唯一标识 -- 信息摘要。比如可以：

- 从图片二进制的开头取 100 个字节
- 中间取 100 个字节
- 最后取 100 个字节

然后将这 300 个字节放到一起，通过 Hash 算法得到一个 Hash 值，作为图片的唯一标示，然后在 Hash 表中查找是否存在该唯一标识即可。

### 数据校验

BT 下载的原理是 P2P 协议，当你从多个机器上下载一个 2GB 的电影，这个电影文件可能被划分为多个文件块（以划分为 100 块为例），所有的文件块下载完后，再组装为一个完整的电影文件即可。

但是网络传输是不安全的，下载的文件块可能被宿主机器恶意修改、或者下载过程中出错了导致下载的文件块不完整，该如何校验恶意修改或下载出错的情况？

检验的方式有很多，一种简单的思路是：通过 Hash 算法，对每个文件块分别取 Hash 值并保存在 BT 文件中。利用 Hash 算法对输入数据敏感的特点，只要文件块的内容有一丁点的改变，最后计算出的 Hash 值也会完全不同。

### Hash 函数

Hash 函数是散列表的关键，它决定了散列冲突的概率和散列表的性能。Hash 函数对 Hash 算法的要求低很多，因为即使出现散列冲突，只要不严重也可以通过开放寻址法或链表法解决。

而且 Hash 函数对 Hash 算法计算的 Hash 值是否可以反向解密也不关心，**Hash 函数更关注计算得到的 Hash 值是否能平衡分布**。

## 分布式系统中的应用

### 负载均衡

负载均衡算法很多：

- 轮询
- 随机
- 加权轮询等

但是该如何实现一个会话粘滞（session sticky，也叫会话保持）的负载均衡算法？

先解释一下会话保持的负载均衡：在同一个客户端上，在一次会话中的所有请求都路由到同一台服务器。

最直接的方法是：维护一张映射关系表，表的内容是【客户端的 IP 地址】（或会话 ID）与服务器编号的映射关系。客户端发出的请求，都通过映射表找到服务器编号，然后再请求编号对应的服务器。

这个方法虽然简单，但也有几个弊端：

- 如果客户端很多，映射表就会很大，浪费内存空间
- 维护映射表的成本很大。客户端下线、上线，服务器扩容、缩容都会导致映射失效

借助 Hash 算法，可以非常完美的解决这些问题：

- 通过 Hash 算法对客户端的 IP 地址（或会话 ID）计算 Hash 值
- 将得到的 Hash 值与服务器列表的大小进行取模运算
- 最终得到的值是对应的服务器编号

这样就可以把同一个 IP 过来的所有请求都路由到同一台服务器了。

### 数据分片

哈希算法还可以用于数据的分片，举两个例子。

#### 统计“搜索关键词”出现的次数

假如有 1T 的日志文件，里面记录了用户的搜索关键词，怎样可以快速统计出每个关键词被搜索的次数？

分析一下这个问题的难点：

- 日志很大，没办法放到一台机器内存中
- 如果只用一台机器处理这么大的数据，处理时间会很长

处理这两个难点：

- 先对数据进行分片
- 然后采用多台机器处理的方法，来提高处理速度

具体思路：为了提高处理的速度，用 n 台机器并行处理。

从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过 Hash 函数计算 Hash 值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。

这样，Hash 值相同的搜索关键词就被分配到了同一个机器上。也就是说，同一个搜索关键词会被分配到同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。

实际上这也是 MapReduce 的基本设计思想。

#### 快速判断图片是否在图库中

[之前](/search/hash.html#唯一标示)讲过这个例子，通过给每个图片取信息摘要，然后构建散列表的方式实现。

如果现在图库中有 1 亿张图片，在单台机器上构建散列表很显然就行不通了。那么该怎么办呢？

同样可以先对数据分片，然后采用多机处理的方式。

准备 n 台机器，让每台机器只维护某一部分图片对应的散列表：

- 每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号
- 然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表
- 当要判断一个图片是否在图库中的时候，通过同样的 Hash 算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模
- 假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找

估算一下给 1 亿张图片构建散列表大概需要多少台机器。

散列表中每个数据单元包含两个信息：

- 哈希值：假设我们通过 MD5 来计算哈希值，那长度就是 128 比特，也就是 16 字节
- 图片文件的路径：
  - 文件路径长度的上限是 256 字节，我们可以假设平均长度是 128 字节
  - 如果用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节

假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB * 0.75 / 152）张图片构建散列表。所以，如果要对 1 亿张图片构建索引，需要大约十几台机器。

在工程中，这种估算还是很重要的，能让我们事先对需要投入的资源、资金有个大概的了解，能更好地评估解决方案的可行性。

### 分布式存储 - 一致性 Hash 算法

现在互联网面对的都是海量的数据、海量的用户。为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。当有海量的数据需要缓存时，一个缓存机器肯定是不够的，于是我们就需要将数据分布在多台机器上。

该如何决定将哪个数据放到哪个机器上呢？

可以借用前面[数据分片](/search/hash.html#数据分片)的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。

但是，如果数据增多，原来的 10 个机器已经无法承受了，就需要扩容了，比如扩到 11 个机器，这时候麻烦就来了。注意这里并不是简单地加个机器就可以了。

原来的数据是通过与 10 来取模的。比如 13 这个数据，存储在编号为 3 这台机器上；但是新加了一台机器中，我们对数据按照 11 取模，原来 13 这个数据就被分配到 2 号这台机器上了。

因此所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。这样就相当于，缓存中的数据一下子就都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生[雪崩效应](https://zh.wikipedia.org/wiki/%E9%9B%AA%E5%B4%A9%E6%95%88%E5%BA%94)，压垮数据库。

#### 一致性 Hash 算法

我们需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移 -- [一致性 Hash 算法](https://en.wikipedia.org/wiki/Consistent_hashing)。

假设我们有 k 个机器，数据的 Hash 值的范围是[0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。

<!-- TODO -->
这是一致性 Hash 算法的基本思想，具体请自行了解。

## 思考

### 存储用户密码

- 如何防止数据库中的用户信息被脱库？

通过哈希算法，对用户密码进行加密之后再存储，不过最好选择相对安全的加密算法，比如 SHA 等（因为 MD5 已经号称被破解了）。

- 不过仅仅这样加密之后存储就万事大吉了吗？

如果用户信息被“脱库”，黑客虽然拿到是加密之后的密文，但可以通过“猜”的方式来破解密码。因为有些用户的密码太简单，比如很多人习惯用 00000、123456 这样的简单数字组合做密码，很容易就被猜中。

- **字典攻击**你听说过吗？

维护一个常用密码的字典表，把字典中的每个密码用 Hash 算法计算 Hash 值，然后拿 Hash 值跟脱库后的密文比对。

如果相同，基本上就可以认为，这个加密之后的密码对应的明文就是字典中的这个密码。（注意，这里说是的是“基本上可以认为”，因为根据前面的学习，Hash 算法存在散列冲突，所以也有可能出现，尽管密文一样，但是明文并不一样的情况。）

- 那么该怎么办呢？

**针对字典攻击，可以引入盐**（salt），跟用户的密码组合在一起，增加密码的复杂度。用组合之后的字符串来做哈希算法加密，将它存储到数据库中，进一步增加破解的难度。

最后，安全和攻击是一种博弈关系，不存在绝对的安全，所有的安全措施，只是增加攻击的成本而已。

### 区块链

区块链是一块块区块组成的，每个区块分为两部分：

- 区块头：保存着 自己区块体 和 上一个区块头 的哈希值
- 区块体

通过这种链式关系和哈希值的唯一性，只要区块链上任意一个区块被修改过，后面所有区块保存的哈希值就不对了。

区块链使用的是 SHA256 哈希算法，计算哈希值非常耗时，如果要篡改一个区块，就必须重新计算该区块后面所有的区块的哈希值，短时间内几乎不可能做到。
